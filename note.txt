import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

# Initialize the PorterStemmer
ps = PorterStemmer()

# Initialize the corpus list
corpus = []

# Load the stopwords
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

for i in range(0, 5572):
    # Applying Regular Expression
    '''
    Replace email addresses with 'emailaddr'
    Replace URLs with 'httpaddr'
    Replace money symbols with 'moneysymb'
    Replace phone numbers with 'phonenumbr'
    Replace numbers with 'numbr'
    '''
    msg = df['message'][i]
    msg = re.sub(r'\b[\w\-.]+?@\w+?\.\w{2,4}\b', 'emailaddr', msg)
    msg = re.sub(r'(http[s]?\S+)|(\w+\.[A-Za-z]{2,4}\S*)', 'httpaddr', msg)
    msg = re.sub(r'Â£|\$', 'moneysymb', msg)
    msg = re.sub(r'\b(\+\d{1,2}\s)?\d?[\-(.]?\d{3}\)?[\s.-]?\d{3}[\s.-]?\d{4}\b', 'phonenumbr', msg)
    msg = re.sub(r'\d+(\.\d+)?', 'numbr', msg)

    # Remove all punctuations
    msg = re.sub(r'[^\w\d\s]', ' ', msg)

    if i < 2:
        print("\t\t\t\t MESSAGE ", i)

    if i < 2:
        print("\n After Regular Expression - Message ", i, " : ", msg)

    # Convert each word to lowercase
    msg = msg.lower()
    if i < 2:
        print("\n Lower case Message ", i, " : ", msg)

    # Split the words to tokenize
    msg = msg.split()
    if i < 2:
        print("\n After Splitting - Message ", i, " : ", msg)

    # Stemming with PorterStemmer and remove stopwords
    msg = [ps.stem(word) for word in msg if word not in stop_words]
    if i < 2:
        print("\n After Stemming - Message ", i, " : ", msg)

    # Prepare the message with remaining tokens
    msg = ' '.join(msg)
    if i < 2:
        print("\n Final Prepared - Message ", i, " : ", msg, "\n\n")

    # Add the message to the corpus
    corpus.append(msg)





from sklearn.feature_extraction.text import CountVectorizer

# Create an instance of CountVectorizer
vectorizer = CountVectorizer()

# Convert the corpus list into a bag-of-words matrix
count_matrix = vectorizer.fit_transform(corpus)

# Create a DataFrame with the count matrix and feature names as columns
df1 = pd.DataFrame(data=count_matrix.toarray(), columns=vectorizer.get_feature_names_out())

# Display the DataFrame
df1.head()
